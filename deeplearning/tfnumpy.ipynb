{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 17:51:20.486757: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-02 17:51:20.509899: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-02 17:51:20.509929: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-02 17:51:20.509953: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-02 17:51:20.514836: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 17:52:40.118656: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2024-07-02 17:52:40.118674: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: lkk-intel12\n",
      "2024-07-02 17:52:40.118677: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: lkk-intel12\n",
      "2024-07-02 17:52:40.118728: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: 535.183.1\n",
      "2024-07-02 17:52:40.118736: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 535.183.1\n",
      "2024-07-02 17:52:40.118738: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:309] kernel version seems to match DSO: 535.183.1\n"
     ]
    }
   ],
   "source": [
    "Basefolder = \"../data/\"\n",
    "h_hat_pilot_tf=np.load(Basefolder+'h_hat_pilot_tf.npy') #(2, 1, 16, 1, 2, 128)\n",
    "h_hat_pilot=np.load(Basefolder+'h_hat_pilot.npy') \n",
    "print(np.allclose(h_hat_pilot_tf, h_hat_pilot)) #True\n",
    "\n",
    "inter_gather_ind_tf=np.load(Basefolder+'inter_gather_ind_tf.npy') #(1, 2, 14, 64)\n",
    "inter_gather_ind=np.load(Basefolder+'inter_gather_ind.npy') \n",
    "print(np.allclose(inter_gather_ind_tf, inter_gather_ind)) #True\n",
    "\n",
    "inputs_inter_tf=np.load(Basefolder+'inputs_inter_tf.npy') #(1, 2, 128, 1, 1, 1)\n",
    "inputs_inter=np.load(Basefolder+'inputs_inter.npy') #(1, 2, 128, 1, 1, 1)\n",
    "print(np.allclose(inputs_inter_tf, inputs_inter)) #True\n",
    "\n",
    "outputs_inter_tf=np.load(Basefolder+'outputs_inter_tf.npy') #(1, 2, 14, 64, 1, 1, 1)\n",
    "outputs_inter=np.load(Basefolder+'outputs_inter.npy') #(1, 2, 14, 64, 1, 1, 1)\n",
    "print(np.allclose(outputs_inter_tf, outputs_inter)) #False\n",
    "\n",
    "#tf.gather to extract specific indices from a single axis of a tensor.\n",
    "#[num_tx, num_streams_per_tx, num_pilots, k, l, m]\n",
    "#inputs_inter_tf(1, 2, 128, 1, 1, 1)  inter_gather_ind_tf: (1, 2, 14, 64)\n",
    "outputs_tf = tf.gather(inputs_inter_tf, inter_gather_ind_tf, 2, batch_dims=2) #(1, 2, 14, 64, 1, 1, 1)\n",
    "print(np.allclose(outputs_inter_tf, outputs_tf)) #True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]]\n"
     ]
    }
   ],
   "source": [
    "print(inter_gather_ind_tf[:,:,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 14)\n",
      "[[[ 0  0  0  0  0  0  0 64 64 64 64 64 64 64]\n",
      "  [ 1  1  1  1  1  1  1 65 65 65 65 65 65 65]]]\n"
     ]
    }
   ],
   "source": [
    "tmp=inter_gather_ind_tf[:,:,:,0]\n",
    "print(tmp.shape)\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14,)\n",
      "[ 0  0  0  0  0  0  0 64 64 64 64 64 64 64]\n"
     ]
    }
   ],
   "source": [
    "tmp=inter_gather_ind_tf[0,0,:,0]\n",
    "print(tmp.shape)\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14,)\n",
      "[ 1  1  1  1  1  1  1 65 65 65 65 65 65 65]\n"
     ]
    }
   ],
   "source": [
    "tmp=inter_gather_ind_tf[0,1,:,0]\n",
    "print(tmp.shape)\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14,)\n",
      "[ 0  0  0  0  0  0  0 64 64 64 64 64 64 64]\n"
     ]
    }
   ],
   "source": [
    "tmp=inter_gather_ind_tf[0,0,:,1]\n",
    "print(tmp.shape)\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 14)\n",
      "[[[ 0  0  0  0  0  0  0 64 64 64 64 64 64 64]\n",
      "  [ 1  1  1  1  1  1  1 65 65 65 65 65 65 65]]]\n"
     ]
    }
   ],
   "source": [
    "tmp=inter_gather_ind_tf[:,:,:,1]\n",
    "print(tmp.shape)\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 14)\n",
      "[[[ 2  2  2  2  2  2  2 66 66 66 66 66 66 66]\n",
      "  [ 1  1  1  1  1  1  1 65 65 65 65 65 65 65]]]\n"
     ]
    }
   ],
   "source": [
    "tmp=inter_gather_ind_tf[:,:,:,2]\n",
    "print(tmp.shape)\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.00039528]]\n",
      "\n",
      "  [[0.        ]]]]\n"
     ]
    }
   ],
   "source": [
    "print(inputs_inter_tf[:,:,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128,)\n",
      "[0.00039528 0.         0.00039528 0.         0.00039528 0.\n",
      " 0.00039528 0.         0.00039528 0.         0.00039528 0.\n",
      " 0.00039528 0.         0.00039528 0.         0.00039528 0.\n",
      " 0.00039528 0.         0.00039528 0.         0.00039528 0.\n",
      " 0.00039528 0.         0.00039528 0.         0.00039528 0.\n",
      " 0.00039528 0.         0.00039528 0.         0.00039528 0.\n",
      " 0.00039528 0.         0.00039528 0.         0.00039528 0.\n",
      " 0.00039528 0.         0.00039528 0.         0.00039528 0.\n",
      " 0.00039528 0.         0.00039528 0.         0.00039528 0.\n",
      " 0.00039528 0.         0.00039528 0.         0.00039528 0.\n",
      " 0.00039528 0.         0.00039528 0.         0.00039528 0.\n",
      " 0.00039528 0.         0.00039528 0.         0.00039528 0.\n",
      " 0.00039528 0.         0.00039528 0.         0.00039528 0.\n",
      " 0.00039528 0.         0.00039528 0.         0.00039528 0.\n",
      " 0.00039528 0.         0.00039528 0.         0.00039528 0.\n",
      " 0.00039528 0.         0.00039528 0.         0.00039528 0.\n",
      " 0.00039528 0.         0.00039528 0.         0.00039528 0.\n",
      " 0.00039528 0.         0.00039528 0.         0.00039528 0.\n",
      " 0.00039528 0.         0.00039528 0.         0.00039528 0.\n",
      " 0.00039528 0.         0.00039528 0.         0.00039528 0.\n",
      " 0.00039528 0.         0.00039528 0.         0.00039528 0.\n",
      " 0.00039528 0.        ]\n"
     ]
    }
   ],
   "source": [
    "tmp=inputs_inter_tf[0,0,:,0,0,0]\n",
    "print(tmp.shape)\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.gather: https://github.com/tensorflow/tensorflow/blob/v2.16.1/tensorflow/python/ops/array_ops.py#L4963-L4977\n",
    "https://www.tensorflow.org/api_docs/python/tf/gather"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The params may also have any shape. gather can select slices across any axis depending on the axis argument (which defaults to 0). Below it is used to gather first rows, then columns from a matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3)\n",
      "(2, 3)\n",
      "[[30. 31. 32.]\n",
      " [10. 11. 12.]]\n"
     ]
    }
   ],
   "source": [
    "params = tf.constant([[0, 1.0, 2.0],\n",
    "                      [10.0, 11.0, 12.0],\n",
    "                      [20.0, 21.0, 22.0],\n",
    "                      [30.0, 31.0, 32.0]])\n",
    "print(params.shape)\n",
    "result = tf.gather(params, indices=[3,1]).numpy() #it means select row (3: 30.0, 31.0, 32.0), and row (1: 10.0, 11.0, 12.0)\n",
    "print(result.shape)\n",
    "print(result)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2)\n",
      "[[ 2.  1.]\n",
      " [12. 11.]\n",
      " [22. 21.]\n",
      " [32. 31.]]\n"
     ]
    }
   ],
   "source": [
    "result =tf.gather(params, indices=[2,1], axis=1).numpy() #it means select column 2 and column 1\n",
    "print(result.shape)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t=torch.tensor([[1,2,3],\n",
    "                [4,5,6],\n",
    "                [7,8,9],\n",
    "                [10,11,12]])\n",
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "tensor([[ 1,  5, 12],\n",
      "        [10,  5,  9]])\n"
     ]
    }
   ],
   "source": [
    "#gather at dim=0, means select row\n",
    "index_dim0 = torch.tensor([[0,1,3],\n",
    "                           [3,1,2]]) #Shape is (2,3)\n",
    "result = torch.gather(t, dim=0, index=index_dim0)\n",
    "print(result.shape)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My understanding: when index is 2-d, the output is the same shape as the index. dim=0 means the select row, the first index row [0,1,3] means select the index-mapped rows, while keep the order of the column as in the index. Output 0-col: select 0-row (1), 1-col: select 1-row (5), 2-col: select 3-row (12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tfgather1.png](../imgs/tfgather1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  2,  3],\n",
       "        [ 4,  5,  6],\n",
       "        [ 7,  8,  9],\n",
       "        [10, 11, 12]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2])\n",
      "tensor([[ 1,  3],\n",
      "        [ 5,  4],\n",
      "        [ 7,  9],\n",
      "        [11, 10]])\n"
     ]
    }
   ],
   "source": [
    "#dim=1, select column\n",
    "index_dim1 = torch.tensor([[0,2],\n",
    "                           [1,0],\n",
    "                           [0,2],\n",
    "                           [1,0]]) #Shape is (4,2)\n",
    "result=torch.gather(t, dim=1, index=index_dim1)\n",
    "print(result.shape)\n",
    "print(result)# [0,1]select the 0-col (1), and 2-col (3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tfgather2.png](../imgs/tfgather2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The batch_dims argument lets you gather different items from each element of a batch.\n",
    "\n",
    "Using batch_dims=1 is equivalent to having an outer loop over the first axis of params and indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 5)\n",
      "(3, 2)\n"
     ]
    }
   ],
   "source": [
    "params = tf.constant([\n",
    "    [0, 0, 1, 0, 2],\n",
    "    [3, 0, 0, 0, 4],\n",
    "    [0, 5, 0, 6, 0]])\n",
    "print(params.shape)\n",
    "indices = tf.constant([\n",
    "    [2, 4],\n",
    "    [0, 4],\n",
    "    [1, 3]])\n",
    "print(indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n"
     ]
    }
   ],
   "source": [
    "result = tf.gather(params, indices, axis=1, batch_dims=1).numpy()\n",
    "print(result.shape)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2)\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n"
     ]
    }
   ],
   "source": [
    "def manually_batched_gather(params, indices, axis, batch_dims=1):\n",
    "  result = []\n",
    "  for p,i in zip(params, indices):\n",
    "    r = tf.gather(p, i, axis=axis-batch_dims)\n",
    "    result.append(r)\n",
    "  return tf.stack(result)\n",
    "result =manually_batched_gather(params, indices, axis=1).numpy()\n",
    "print(result.shape)\n",
    "print(result)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 5)\n",
      "(3, 2)\n"
     ]
    }
   ],
   "source": [
    "params = tf.constant([[\n",
    "    [0, 0, 1, 0, 2],\n",
    "    [3, 0, 0, 0, 4],\n",
    "    [0, 5, 0, 6, 0]]])\n",
    "print(params.shape)\n",
    "indices = tf.constant([\n",
    "    [2, 4],\n",
    "    [0, 4],\n",
    "    [1, 3]])\n",
    "print(indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 2)\n",
      "[[[1 2]\n",
      "  [0 4]\n",
      "  [0 0]]]\n"
     ]
    }
   ],
   "source": [
    "result =manually_batched_gather(params, indices, axis=1, batch_dims=2).numpy()\n",
    "print(result.shape)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "[[0 2]\n",
      " [1 0]]\n",
      "(2, 2)\n",
      "[[1 3]\n",
      " [5 4]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def gather_numpy(params, indices, axis):\n",
    "    # Assuming params and indices are NumPy arrays\n",
    "    # params: The tensor from which to gather values\n",
    "    # indices: The indices to gather\n",
    "    # axis: The axis along which to index\n",
    "    \n",
    "    # Use np.take_along_axis to gather values\n",
    "    gathered_values = np.take_along_axis(params, indices, axis=axis)\n",
    "    \n",
    "    return gathered_values\n",
    "\n",
    "# Example usage\n",
    "params = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(params)\n",
    "indices = np.array([[0, 2], [1, 0]])\n",
    "print(indices)\n",
    "result = gather_numpy(params, indices, axis=1)\n",
    "print(result.shape)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numpy_gather(params, indices, validate_indices=None, axis=None, batch_dims=0):\n",
    "    gather_ind_nobatch = indices[0, 0] #ignore first two dimensions as batch (14, 64)\n",
    "    outputs = np.take(params, gather_ind_nobatch, axis=2) #(1, 2, 14, 64, 2, 1, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_inter_np = np.random.rand(1, 2, 128, 1, 1, 1)\n",
    "inter_gather_ind_np = np.random.randint(0, 14, size=(1, 2, 14, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_gather(inputs_inter_np, inter_gather_ind_np, validate_indices=None, axis=None, batch_dims=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result shape: (1, 2, 14, 64, 1, 1, 1)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def gather_numpy(inputs, indices, batch_dims=2):\n",
    "    # Ensure the batch_dims is within the valid range\n",
    "    if batch_dims < 0 or batch_dims >= len(inputs.shape):\n",
    "        raise ValueError(\"Invalid batch_dims value\")\n",
    "\n",
    "    # Initialize the result tensor\n",
    "    result = inputs.copy() #(1, 2, 128, 1, 1, 1)\n",
    "\n",
    "    # Gather along each dimension\n",
    "    # for dim in range(batch_dims, len(inputs.shape)): #2-6\n",
    "    #     result = np.take(result, indices, axis=dim)\n",
    "\n",
    "    #gather_ind_nobatch = indices[0, 0] #ignore first two dimensions as batch (14, 64)\n",
    "    #result = np.take(result, gather_ind_nobatch, axis=2) #(1, 2, 14, 64, 2, 1, 16)\n",
    "    gather_ind_nobatch = indices[0, 0] #ignore first two dimensions as batch (14, 64)\n",
    "    result1 = np.take(result, gather_ind_nobatch, axis=2) #(1, 2, 14, 64, 2, 1, 16)\n",
    "    gather_ind_nobatch = indices[0, 1] #ignore first two dimensions as batch (14, 64)\n",
    "    result = np.take(result, gather_ind_nobatch, axis=2) #(1, 2, 14, 64, 2, 1, 16)\n",
    "    result[0,0,:,:,:,:,:]=result1[0,0,:,:,:,:,:]\n",
    "\n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "inputs_inter_np = np.random.rand(1, 2, 128, 1, 1, 1)\n",
    "inter_gather_ind_np = np.random.randint(0, 14, size=(1, 2, 14, 64))\n",
    "result = gather_numpy(inputs_inter_np, inter_gather_ind_np, batch_dims=2)\n",
    "\n",
    "print(\"Result shape:\", result.shape)  # Should be (1, 2, 14, 64, 1, 1, 1)\n",
    "\n",
    "result_tf = tf.gather(inputs_inter_np, inter_gather_ind_np, 2, batch_dims=2) #(1, 2, 14, 64, 1, 1, 1)\n",
    "print(np.allclose(result, result_tf)) #True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result shape: (1, 2, 14, 64, 1, 1, 1)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "def gather_numpy(inputs, indices, batch_dims=2):\n",
    "    # Ensure the batch_dims is within the valid range\n",
    "    if batch_dims < 0 or batch_dims >= len(inputs.shape):\n",
    "        raise ValueError(\"Invalid batch_dims value\")\n",
    "    result = inputs.copy()\n",
    "    # Gather along each dimension\n",
    "    # for dim in range(batch_dims, len(inputs.shape)): #2-6\n",
    "    #     result = np.take(result, indices, axis=dim)\n",
    "\n",
    "    #gather_ind_nobatch = indices[0, 0] #ignore first two dimensions as batch (14, 64)\n",
    "    #result = np.take(result, gather_ind_nobatch, axis=2) #(1, 2, 14, 64, 2, 1, 16)\n",
    "    gather_ind_nobatch = indices[0, 0] #ignore first two dimensions as batch (14, 64)\n",
    "    result1 = np.take(result, gather_ind_nobatch, axis=2) #(1, 2, 14, 64, 2, 1, 16)\n",
    "    gather_ind_nobatch = indices[0, 1] #ignore first two dimensions as batch (14, 64)\n",
    "    result = np.take(result, gather_ind_nobatch, axis=2) #(1, 2, 14, 64, 2, 1, 16)\n",
    "    result[0,0,:,:,:,:,:]=result1[0,0,:,:,:,:,:]\n",
    "\n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "inputs_inter_np = np.random.rand(1, 2, 128, 1, 1, 1)\n",
    "inter_gather_ind_np = np.random.randint(0, 14, size=(1, 2, 14, 64))\n",
    "result_np = gather_numpy(inputs_inter_np, inter_gather_ind_np, batch_dims=2)\n",
    "\n",
    "print(\"Result shape:\", result.shape)  # Should be (1, 2, 14, 64, 1, 1, 1)\n",
    "\n",
    "result_tf = tf.gather(inputs_inter_np, inter_gather_ind_np, 2, batch_dims=2) #(1, 2, 14, 64, 1, 1, 1)\n",
    "print(np.allclose(result_np, result_tf)) #True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 128, 1, 1, 1)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_inter_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_dims=2\n",
    "axis = 2\n",
    "shape1=inputs_inter_np.shape[0:batch_dims]\n",
    "shape2=inputs_inter_np.shape[axis+1:]\n",
    "shape3=inter_gather_ind_np.shape[batch_dims:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "newshape=shape1+shape3+shape2 #tuple add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 14, 64, 1, 1, 1)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 1)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_numpy2(inputs, indices, gt, axis=2, batch_dims=2):\n",
    "    shape1=inputs.shape[0:batch_dims]\n",
    "    shape2=inputs.shape[axis+1:]\n",
    "    shape3=indices.shape[batch_dims:]\n",
    "    newshape=shape1+shape3+shape2 #tuple add\n",
    "    print(\"newshape:\",newshape)\n",
    "    output = np.zeros(newshape)\n",
    "\n",
    "    loops=indices.shape[batch_dims-1] #2\n",
    "    print(\"loops\", loops)\n",
    "    \n",
    "\n",
    "    for dim in range(0, loops):\n",
    "        gather_ind_nobatch = indices[0, dim]\n",
    "        result = np.take(inputs, gather_ind_nobatch, axis)\n",
    "        print(\"result:\",result.shape)\n",
    "        output[0,dim,:,:,:,:,:]=result[0,dim,:,:,:,:,:].copy()\n",
    "        #result[0,0,:,:,:,:,:]=result1[0,0,:,:,:,:,:]\n",
    "        print(np.allclose(result[0,dim,:,:,:,:,:], gt[0,dim,:,:,:,:,:])) #True\n",
    "    \n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newshape: (1, 2, 14, 64, 1, 1, 1)\n",
      "loops 2\n",
      "result: (1, 2, 14, 64, 1, 1, 1)\n",
      "False\n",
      "result: (1, 2, 14, 64, 1, 1, 1)\n",
      "False\n",
      "Result shape: (1, 2, 14, 64, 1, 1, 1)\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "result_tf = tf.gather(inputs_inter_np, inter_gather_ind_np, 2, batch_dims=2) #(1, 2, 14, 64, 1, 1, 1)\n",
    "\n",
    "inputs_inter_np = np.random.rand(1, 2, 128, 1, 1, 1)\n",
    "inter_gather_ind_np = np.random.randint(0, 14, size=(1, 2, 14, 64))\n",
    "result = gather_numpy2(inputs_inter_np, inter_gather_ind_np, result_tf, batch_dims=2)\n",
    "\n",
    "print(\"Result shape:\", result.shape)  # Should be (1, 2, 14, 64, 1, 1, 1)\n",
    "\n",
    "\n",
    "print(np.allclose(result, result_tf)) #True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 2, 14, 64, 1, 1, 1])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(np.allclose(result[0,0,:,:,:,:], result_tf[0,0,:,:,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(np.allclose(result[0,:,:,:,:,:], result_tf[0,:,:,:,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(np.allclose(result[:,0,:,:,:,:], result_tf[:,0,:,:,:,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.06084636]]]\n",
      "\n",
      "\n",
      " [[[0.3385086 ]]]\n",
      "\n",
      "\n",
      " [[[0.15296875]]]\n",
      "\n",
      "\n",
      " [[[0.51489305]]]\n",
      "\n",
      "\n",
      " [[[0.0065215 ]]]\n",
      "\n",
      "\n",
      " [[[0.78731498]]]\n",
      "\n",
      "\n",
      " [[[0.36026969]]]\n",
      "\n",
      "\n",
      " [[[0.51489305]]]\n",
      "\n",
      "\n",
      " [[[0.0065215 ]]]\n",
      "\n",
      "\n",
      " [[[0.0065215 ]]]\n",
      "\n",
      "\n",
      " [[[0.0065215 ]]]\n",
      "\n",
      "\n",
      " [[[0.15296875]]]\n",
      "\n",
      "\n",
      " [[[0.36026969]]]\n",
      "\n",
      "\n",
      " [[[0.43951321]]]\n",
      "\n",
      "\n",
      " [[[0.3385086 ]]]\n",
      "\n",
      "\n",
      " [[[0.7891132 ]]]\n",
      "\n",
      "\n",
      " [[[0.0065215 ]]]\n",
      "\n",
      "\n",
      " [[[0.3385086 ]]]\n",
      "\n",
      "\n",
      " [[[0.43951321]]]\n",
      "\n",
      "\n",
      " [[[0.0065215 ]]]\n",
      "\n",
      "\n",
      " [[[0.15296875]]]\n",
      "\n",
      "\n",
      " [[[0.06084636]]]\n",
      "\n",
      "\n",
      " [[[0.0065215 ]]]\n",
      "\n",
      "\n",
      " [[[0.5466175 ]]]\n",
      "\n",
      "\n",
      " [[[0.78731498]]]\n",
      "\n",
      "\n",
      " [[[0.15296875]]]\n",
      "\n",
      "\n",
      " [[[0.28738122]]]\n",
      "\n",
      "\n",
      " [[[0.43951321]]]\n",
      "\n",
      "\n",
      " [[[0.15296875]]]\n",
      "\n",
      "\n",
      " [[[0.82570204]]]\n",
      "\n",
      "\n",
      " [[[0.51489305]]]\n",
      "\n",
      "\n",
      " [[[0.3385086 ]]]\n",
      "\n",
      "\n",
      " [[[0.78731498]]]\n",
      "\n",
      "\n",
      " [[[0.3385086 ]]]\n",
      "\n",
      "\n",
      " [[[0.78731498]]]\n",
      "\n",
      "\n",
      " [[[0.3385086 ]]]\n",
      "\n",
      "\n",
      " [[[0.3385086 ]]]\n",
      "\n",
      "\n",
      " [[[0.60340964]]]\n",
      "\n",
      "\n",
      " [[[0.15296875]]]\n",
      "\n",
      "\n",
      " [[[0.06084636]]]\n",
      "\n",
      "\n",
      " [[[0.5466175 ]]]\n",
      "\n",
      "\n",
      " [[[0.87904344]]]\n",
      "\n",
      "\n",
      " [[[0.06084636]]]\n",
      "\n",
      "\n",
      " [[[0.87904344]]]\n",
      "\n",
      "\n",
      " [[[0.82570204]]]\n",
      "\n",
      "\n",
      " [[[0.36026969]]]\n",
      "\n",
      "\n",
      " [[[0.43951321]]]\n",
      "\n",
      "\n",
      " [[[0.7891132 ]]]\n",
      "\n",
      "\n",
      " [[[0.78731498]]]\n",
      "\n",
      "\n",
      " [[[0.87904344]]]\n",
      "\n",
      "\n",
      " [[[0.0065215 ]]]\n",
      "\n",
      "\n",
      " [[[0.82570204]]]\n",
      "\n",
      "\n",
      " [[[0.60340964]]]\n",
      "\n",
      "\n",
      " [[[0.3385086 ]]]\n",
      "\n",
      "\n",
      " [[[0.78731498]]]\n",
      "\n",
      "\n",
      " [[[0.5466175 ]]]\n",
      "\n",
      "\n",
      " [[[0.82570204]]]\n",
      "\n",
      "\n",
      " [[[0.87904344]]]\n",
      "\n",
      "\n",
      " [[[0.36026969]]]\n",
      "\n",
      "\n",
      " [[[0.60340964]]]\n",
      "\n",
      "\n",
      " [[[0.28738122]]]\n",
      "\n",
      "\n",
      " [[[0.5466175 ]]]\n",
      "\n",
      "\n",
      " [[[0.15296875]]]\n",
      "\n",
      "\n",
      " [[[0.0065215 ]]]]\n"
     ]
    }
   ],
   "source": [
    "print(result[0,0,0,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0.06084636]]]\n",
      "\n",
      "\n",
      " [[[0.3385086 ]]]\n",
      "\n",
      "\n",
      " [[[0.15296875]]]\n",
      "\n",
      "\n",
      " [[[0.51489305]]]\n",
      "\n",
      "\n",
      " [[[0.0065215 ]]]\n",
      "\n",
      "\n",
      " [[[0.78731498]]]\n",
      "\n",
      "\n",
      " [[[0.36026969]]]\n",
      "\n",
      "\n",
      " [[[0.51489305]]]\n",
      "\n",
      "\n",
      " [[[0.0065215 ]]]\n",
      "\n",
      "\n",
      " [[[0.0065215 ]]]\n",
      "\n",
      "\n",
      " [[[0.0065215 ]]]\n",
      "\n",
      "\n",
      " [[[0.15296875]]]\n",
      "\n",
      "\n",
      " [[[0.36026969]]]\n",
      "\n",
      "\n",
      " [[[0.43951321]]]\n",
      "\n",
      "\n",
      " [[[0.3385086 ]]]\n",
      "\n",
      "\n",
      " [[[0.7891132 ]]]\n",
      "\n",
      "\n",
      " [[[0.0065215 ]]]\n",
      "\n",
      "\n",
      " [[[0.3385086 ]]]\n",
      "\n",
      "\n",
      " [[[0.43951321]]]\n",
      "\n",
      "\n",
      " [[[0.0065215 ]]]\n",
      "\n",
      "\n",
      " [[[0.15296875]]]\n",
      "\n",
      "\n",
      " [[[0.06084636]]]\n",
      "\n",
      "\n",
      " [[[0.0065215 ]]]\n",
      "\n",
      "\n",
      " [[[0.5466175 ]]]\n",
      "\n",
      "\n",
      " [[[0.78731498]]]\n",
      "\n",
      "\n",
      " [[[0.15296875]]]\n",
      "\n",
      "\n",
      " [[[0.28738122]]]\n",
      "\n",
      "\n",
      " [[[0.43951321]]]\n",
      "\n",
      "\n",
      " [[[0.15296875]]]\n",
      "\n",
      "\n",
      " [[[0.82570204]]]\n",
      "\n",
      "\n",
      " [[[0.51489305]]]\n",
      "\n",
      "\n",
      " [[[0.3385086 ]]]\n",
      "\n",
      "\n",
      " [[[0.78731498]]]\n",
      "\n",
      "\n",
      " [[[0.3385086 ]]]\n",
      "\n",
      "\n",
      " [[[0.78731498]]]\n",
      "\n",
      "\n",
      " [[[0.3385086 ]]]\n",
      "\n",
      "\n",
      " [[[0.3385086 ]]]\n",
      "\n",
      "\n",
      " [[[0.60340964]]]\n",
      "\n",
      "\n",
      " [[[0.15296875]]]\n",
      "\n",
      "\n",
      " [[[0.06084636]]]\n",
      "\n",
      "\n",
      " [[[0.5466175 ]]]\n",
      "\n",
      "\n",
      " [[[0.87904344]]]\n",
      "\n",
      "\n",
      " [[[0.06084636]]]\n",
      "\n",
      "\n",
      " [[[0.87904344]]]\n",
      "\n",
      "\n",
      " [[[0.82570204]]]\n",
      "\n",
      "\n",
      " [[[0.36026969]]]\n",
      "\n",
      "\n",
      " [[[0.43951321]]]\n",
      "\n",
      "\n",
      " [[[0.7891132 ]]]\n",
      "\n",
      "\n",
      " [[[0.78731498]]]\n",
      "\n",
      "\n",
      " [[[0.87904344]]]\n",
      "\n",
      "\n",
      " [[[0.0065215 ]]]\n",
      "\n",
      "\n",
      " [[[0.82570204]]]\n",
      "\n",
      "\n",
      " [[[0.60340964]]]\n",
      "\n",
      "\n",
      " [[[0.3385086 ]]]\n",
      "\n",
      "\n",
      " [[[0.78731498]]]\n",
      "\n",
      "\n",
      " [[[0.5466175 ]]]\n",
      "\n",
      "\n",
      " [[[0.82570204]]]\n",
      "\n",
      "\n",
      " [[[0.87904344]]]\n",
      "\n",
      "\n",
      " [[[0.36026969]]]\n",
      "\n",
      "\n",
      " [[[0.60340964]]]\n",
      "\n",
      "\n",
      " [[[0.28738122]]]\n",
      "\n",
      "\n",
      " [[[0.5466175 ]]]\n",
      "\n",
      "\n",
      " [[[0.15296875]]]\n",
      "\n",
      "\n",
      " [[[0.0065215 ]]]], shape=(64, 1, 1, 1), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "print(result_tf[0,0,0,:,:,:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mycondapy310",
   "language": "python",
   "name": "mycondapy310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
